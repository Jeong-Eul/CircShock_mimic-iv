{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "available-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "import importlib\n",
    "import warnings\n",
    "\n",
    "pd.set_option('mode.chained_assignment',  None) \n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) \n",
    "\n",
    "local = '/Users/DAHS/Desktop/circ_mimic_preprocessing_1day/data'\n",
    "root_dir = '/Users/DAHS/MIMIC-IV-Data-Pipeline/MIMIC_pipeline/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f588a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adm():\n",
    "    data=pd.read_csv(local+\"/cohort/cohort_icu_mortality_0_.csv.gz\", compression='gzip', header=0, index_col=None)\n",
    "    data['intime'] = pd.to_datetime(data['intime'])\n",
    "    data['outtime'] = pd.to_datetime(data['outtime'])\n",
    "    data['los']=pd.to_timedelta(data['outtime']-data['intime'],unit='h')\n",
    "    data['los']=data['los'].astype(str)\n",
    "    data[['days', 'dummy','hours']] = data['los'].str.split(' ', -1, expand=True)\n",
    "    data[['hours','min','sec']] = data['hours'].str.split(':', -1, expand=True)\n",
    "    data['los']=pd.to_numeric(data['days'])*24+pd.to_numeric(data['hours'])\n",
    "    data=data.drop(columns=['days', 'dummy','hours','min','sec'])\n",
    "    data=data[data['los']>0]\n",
    "    data['Age']=data['Age'].astype(int)\n",
    "\n",
    "    return data\n",
    "\n",
    "def generate_proc():\n",
    "    proc=pd.read_csv(local+ \"/features/preproc_proc_icu.csv.gz\", compression='gzip', header=0, index_col=None)\n",
    "    proc=proc[proc['stay_id'].isin(data['stay_id'])]\n",
    "    proc[['start_days', 'dummy','start_hours']] = proc['event_time_from_admit'].str.split(' ', -1, expand=True)\n",
    "    proc[['start_hours','min','sec']] = proc['start_hours'].str.split(':', -1, expand=True)\n",
    "    proc['start_time']=pd.to_numeric(proc['start_days'])*24+pd.to_numeric(proc['start_hours'])\n",
    "    proc=proc.drop(columns=['start_days', 'dummy','start_hours','min','sec'])\n",
    "    proc=proc[proc['start_time']>=0]\n",
    "    \n",
    "    ###Remove where event time is after discharge time\n",
    "    proc=pd.merge(proc,data[['stay_id','los']],on='stay_id',how='left')\n",
    "    proc['sanity']=proc['los']-proc['start_time']\n",
    "    proc=proc[proc['sanity']>0]\n",
    "    del proc['sanity']\n",
    "    \n",
    "    return proc\n",
    "\n",
    "\n",
    "def generate_out():\n",
    "    out=pd.read_csv(local+ \"/features/preproc_out_icu.csv.gz\", compression='gzip', header=0, index_col=None)\n",
    "    out=out[out['stay_id'].isin(data['stay_id'])]\n",
    "    out[['start_days', 'dummy','start_hours']] = out['event_time_from_admit'].str.split(' ', -1, expand=True)\n",
    "    out[['start_hours','min','sec']] = out['start_hours'].str.split(':', -1, expand=True)\n",
    "    out['start_time']=pd.to_numeric(out['start_days'])*24+pd.to_numeric(out['start_hours'])\n",
    "    out=out.drop(columns=['start_days', 'dummy','start_hours','min','sec'])\n",
    "    out=out[out['start_time']>=0]\n",
    "    \n",
    "    ###Remove where event time is after discharge time\n",
    "    out=pd.merge(out,data[['stay_id','los']],on='stay_id',how='left')\n",
    "    out['sanity']=out['los']-out['start_time']\n",
    "    out=out[out['sanity']>0]\n",
    "    del out['sanity']\n",
    "    \n",
    "    return out\n",
    "    \n",
    "    \n",
    "def generate_chart():\n",
    "    chunksize = 5000000\n",
    "    final=pd.DataFrame()\n",
    "    for chart in tqdm(pd.read_csv(local+ \"/features/preproc_chart_icu.csv.gz\", compression='gzip', header=0, index_col=None,chunksize=chunksize)):\n",
    "        chart=chart[chart['stay_id'].isin(data['stay_id'])]\n",
    "        chart[['start_days', 'dummy','start_hours']] = chart['event_time_from_admit'].str.split(' ', -1, expand=True)\n",
    "        chart[['start_hours','min','sec']] = chart['start_hours'].str.split(':', -1, expand=True)\n",
    "        chart['start_time']=pd.to_numeric(chart['start_days'])*24+pd.to_numeric(chart['start_hours'])\n",
    "        chart=chart.drop(columns=['start_days', 'dummy','start_hours','min','sec','event_time_from_admit'])\n",
    "        chart=chart[chart['start_time']>=0]\n",
    "\n",
    "        ###Remove where event time is after discharge time\n",
    "        chart=pd.merge(chart,data[['stay_id','los']],on='stay_id',how='left')\n",
    "        chart['sanity']=chart['los']-chart['start_time']\n",
    "        chart=chart[chart['sanity']>0]\n",
    "        del chart['sanity']\n",
    "        del chart['los']\n",
    "        \n",
    "        if final.empty:\n",
    "            final=chart\n",
    "        else:\n",
    "            final=final.append(chart, ignore_index=True)\n",
    "    \n",
    "    return final\n",
    "    \n",
    "\n",
    "def generate_labs():\n",
    "    chunksize = 10000000\n",
    "    final=pd.DataFrame()\n",
    "    for labs in tqdm(pd.read_csv(local+ \"/features/preproc_labs.csv.gz\", compression='gzip', header=0, index_col=None,chunksize=chunksize)):\n",
    "        labs=labs[labs['hadm_id'].isin(data['hadm_id'])]\n",
    "        labs[['start_days', 'dummy','start_hours']] = labs['lab_time_from_admit'].str.split(' ', -1, expand=True)\n",
    "        labs[['start_hours','min','sec']] = labs['start_hours'].str.split(':', -1, expand=True)\n",
    "        labs['start_time']=pd.to_numeric(labs['start_days'])*24+pd.to_numeric(labs['start_hours'])\n",
    "        labs=labs.drop(columns=['start_days', 'dummy','start_hours','min','sec'])\n",
    "        labs=labs[labs['start_time']>=0]\n",
    "\n",
    "        ###Remove where event time is after discharge time\n",
    "        labs=pd.merge(labs,data[['hadm_id','los']],on='hadm_id',how='left')\n",
    "        labs['sanity']=labs['los']-labs['start_time']\n",
    "        labs=labs[labs['sanity']>0]\n",
    "        del labs['sanity']\n",
    "        \n",
    "        if final.empty:\n",
    "            final=labs\n",
    "        else:\n",
    "            final=final.append(labs, ignore_index=True)\n",
    "\n",
    "    return final\n",
    "    \n",
    "    \n",
    "def generate_meds():\n",
    "    meds=pd.read_csv(local+ \"/features/preproc_med_icu.csv.gz\", compression='gzip', header=0, index_col=None)\n",
    "    meds[['start_days', 'dummy','start_hours']] = meds['start_hours_from_admit'].str.split(' ', -1, expand=True)\n",
    "    meds[['start_hours','min','sec']] = meds['start_hours'].str.split(':', -1, expand=True)\n",
    "    meds['start_time']=pd.to_numeric(meds['start_days'])*24+pd.to_numeric(meds['start_hours'])\n",
    "    meds[['start_days', 'dummy','start_hours']] = meds['stop_hours_from_admit'].str.split(' ', -1, expand=True)\n",
    "    meds[['start_hours','min','sec']] = meds['start_hours'].str.split(':', -1, expand=True)\n",
    "    meds['stop_time']=pd.to_numeric(meds['start_days'])*24+pd.to_numeric(meds['start_hours'])\n",
    "    meds=meds.drop(columns=['start_days', 'dummy','start_hours','min','sec'])\n",
    "    #####Sanity check\n",
    "    meds['sanity']=meds['stop_time']-meds['start_time']\n",
    "    meds=meds[meds['sanity']>0]\n",
    "    del meds['sanity']\n",
    "    #####Select hadm_id as in main file\n",
    "    meds=meds[meds['stay_id'].isin(data['stay_id'])]\n",
    "    meds=pd.merge(meds,data[['stay_id','los']],on='stay_id',how='left')\n",
    "\n",
    "    #####Remove where start time is after end of visit\n",
    "    meds['sanity']=meds['los']-meds['start_time']\n",
    "    meds=meds[meds['sanity']>0]\n",
    "    del meds['sanity']\n",
    "    ####Any stop_time after end of visit is set at end of visit\n",
    "    meds.loc[meds['stop_time'] > meds['los'],'stop_time']=meds.loc[meds['stop_time'] > meds['los'],'los']\n",
    "    del meds['los']\n",
    "    \n",
    "    meds['rate']=meds['rate'].apply(pd.to_numeric, errors='coerce')\n",
    "    meds['amount']=meds['amount'].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    return meds\n",
    "    \n",
    "def generate_ing():\n",
    "    ing=pd.read_csv(local+ \"/features/preproc_ing_icu.csv.gz\", compression='gzip', header=0, index_col=None)\n",
    "    ing[['start_days', 'dummy','start_hours']] = ing['start_hours_from_admit'].str.split(' ', -1, expand=True)\n",
    "    ing[['start_hours','min','sec']] = ing['start_hours'].str.split(':', -1, expand=True)\n",
    "    ing['start_time']=pd.to_numeric(ing['start_days'])*24+pd.to_numeric(ing['start_hours'])\n",
    "    ing[['start_days', 'dummy','start_hours']] = ing['stop_hours_from_admit'].str.split(' ', -1, expand=True)\n",
    "    ing[['start_hours','min','sec']] = ing['start_hours'].str.split(':', -1, expand=True)\n",
    "    ing['stop_time']=pd.to_numeric(ing['start_days'])*24+pd.to_numeric(ing['start_hours'])\n",
    "    ing=ing.drop(columns=['start_days', 'dummy','start_hours','min','sec'])\n",
    "    #####Sanity check\n",
    "    ing['sanity']=ing['stop_time']-ing['start_time']\n",
    "    ing=ing[ing['sanity']>0]\n",
    "    del ing['sanity']\n",
    "    #####Select hadm_id as in main file\n",
    "    ing=ing[ing['stay_id'].isin(data['stay_id'])]\n",
    "    ing=pd.merge(ing,data[['stay_id','los']],on='stay_id',how='left')\n",
    "\n",
    "    #####Remove where start time is after end of visit\n",
    "    ing['sanity']=ing['los']-ing['start_time']\n",
    "    ing=ing[ing['sanity']>0]\n",
    "    del ing['sanity']\n",
    "    ####Any stop_time after end of visit is set at end of visit\n",
    "    ing.loc[ing['stop_time'] > ing['los'],'stop_time']=ing.loc[ing['stop_time'] > ing['los'],'los']\n",
    "    del ing['los']\n",
    "    \n",
    "    ing['rate']=ing['rate'].apply(pd.to_numeric, errors='coerce')\n",
    "    ing['amount']=ing['amount'].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    return ing\n",
    "\n",
    "\n",
    "def get_stay_id(labs, chart):\n",
    "            \n",
    "    stay = pd.read_csv(root_dir+\"mimiciv/2.2\"+\"/icu/icustays.csv.gz\")\n",
    "    stay = stay[stay.notna()]\n",
    "    \n",
    "    chart['charttime'] = pd.to_datetime(chart['charttime'])\n",
    "    labs['charttime'] = pd.to_datetime(labs['charttime'])\n",
    "\n",
    "    stay['intime'] = pd.to_datetime(stay['intime'])\n",
    "    stay['outtime'] = pd.to_datetime(stay['outtime'])\n",
    "\n",
    "\n",
    "    labs['stay_id'] = np.nan\n",
    "    result = []\n",
    "\n",
    "    unique_patient_ids = labs['subject_id'].unique()\n",
    "\n",
    "    for p in tqdm(range(len(unique_patient_ids))):\n",
    "        \n",
    "        p_id = unique_patient_ids[p]\n",
    "        \n",
    "        lab = labs[labs['subject_id']==p_id].copy().sort_values('charttime').reset_index(drop=True)\n",
    "        stay_interest = stay[stay['subject_id']==p_id].copy()\n",
    "        \n",
    "        unique_stay_ids = stay_interest['stay_id'].unique()\n",
    "        \n",
    "        for s in  tqdm(range(len(unique_stay_ids)), leave=False):\n",
    "            \n",
    "            stay_id = unique_stay_ids[s]\n",
    "            \n",
    "            stay_interest2 = stay_interest[stay_interest['stay_id']==stay_id].copy()\n",
    "            \n",
    "            indices = np.where((lab['charttime'].values >= stay_interest2['intime'].values) & \n",
    "                            (lab['charttime'].values <= stay_interest2['outtime'].values))\n",
    "\n",
    "            lab['stay_id'].loc[indices[0]] = stay_id\n",
    "\n",
    "            result.append(lab)\n",
    "            \n",
    "    result_df = pd.concat(result)\n",
    "    labs = result_df[~(result_df['stay_id'].isnull())]\n",
    "    return labs\n",
    "\n",
    "data = generate_adm()\n",
    "# ing = generate_ing()\n",
    "# chart = generate_chart()\n",
    "# labs = generate_labs()\n",
    "# labs = get_stay_id(labs, chart)\n",
    "proc = generate_proc()\n",
    "# out = generate_out()\n",
    "# meds = generate_meds()\n",
    "\n",
    "# data.to_csv('check_point_data.csv', compression = 'gzip')\n",
    "# ing.to_csv('check_point_ing.csv', compression = 'gzip')\n",
    "# chart.to_csv('check_point_chart.csv', compression = 'gzip')\n",
    "# labs.to_csv('check_point_labs.csv', compression = 'gzip')\n",
    "# proc.to_csv('check_point_proc.csv', compression = 'gzip')\n",
    "# # out.to_csv('check_point_out.csv', compression = 'gzip')\n",
    "# meds.to_csv('check_point_meds.csv', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "578167bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# data = pd.read_csv('check_point_data.csv', index_col = 0, compression = 'gzip')\n",
    "# ing = pd.read_csv('check_point_ing.csv', index_col = 0, compression = 'gzip')\n",
    "# chart = pd.read_csv('check_point_chart.csv', index_col = 0, compression = 'gzip')\n",
    "# labs = pd.read_csv('check_point_labs.csv', index_col = 0, compression = 'gzip')\n",
    "# proc = pd.read_csv('check_point_proc.csv', index_col = 0, compression = 'gzip')\n",
    "# # out = pd.read_csv('check_point_out.csv', index_col = 0, compression = 'gzip')\n",
    "# meds = pd.read_csv('check_point_meds.csv', index_col = 0, compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4988fd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "include start time 24\n",
      "include end time 1440\n",
      "num of patient:  42253\n",
      "num of stay:  57699\n"
     ]
    }
   ],
   "source": [
    "include_start_time = 1*24\n",
    "include_end_time =60*24\n",
    "\n",
    "def cohort_restirction(include_start_time,include_end_time,data, proc):\n",
    "    print(\"include start time\",include_start_time)\n",
    "    print(\"include end time\",include_end_time)\n",
    "    \n",
    "    data=data[(data['los'] >= include_start_time)]\n",
    "    data=data[(data['los'] <= include_end_time)]\n",
    "    hids=data['stay_id'].unique()\n",
    "    print('num of patient: ', len(data.subject_id.unique()))\n",
    "    print('num of stay: ', len(hids))\n",
    "\n",
    "    # cond=cond[cond['stay_id'].isin(data['stay_id'])]\n",
    "    \n",
    "    # ###MEDS\n",
    "\n",
    "    # meds=meds[meds['stay_id'].isin(data['stay_id'])]\n",
    "    # meds=meds[meds['start_time'] <= include_end_time]\n",
    "    # meds.loc[meds.stop_time > include_end_time, 'stop_time']=include_end_time\n",
    "        \n",
    "    # ###ING\n",
    "\n",
    "    # ing=ing[ing['stay_id'].isin(data['stay_id'])]\n",
    "    # ing=ing[ing['start_time'] <= include_end_time]\n",
    "    # ing.loc[ing.stop_time > include_end_time, 'stop_time']=include_end_time\n",
    "                \n",
    "    \n",
    "    ###PROCS\n",
    "\n",
    "    proc=proc[proc['stay_id'].isin(data['stay_id'])]\n",
    "    proc=proc[proc['start_time']<=include_end_time]\n",
    "        \n",
    "    # ###OUT\n",
    "\n",
    "    # out=out[out['stay_id'].isin(data['stay_id'])]\n",
    "    # out=out[out['start_time']<=include_end_time]\n",
    "        \n",
    "    # ###CHART\n",
    "\n",
    "    # chart=chart[chart['stay_id'].isin(data['stay_id'])]\n",
    "    # chart=chart[chart['start_time']<=include_end_time]\n",
    "        \n",
    "    # ###LAB\n",
    "\n",
    "    # labs=labs[labs['stay_id'].isin(data['stay_id'])]\n",
    "    # labs=labs[labs['start_time']<=include_end_time]\n",
    "    \n",
    "    return  data, proc\n",
    "\n",
    "data_new, proc_new = cohort_restirction(include_start_time,include_end_time ,data, proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca379386",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_meds=pd.DataFrame()\n",
    "final_ing=pd.DataFrame()\n",
    "final_proc=pd.DataFrame()\n",
    "# final_out=pd.DataFrame()\n",
    "final_chart=pd.DataFrame()\n",
    "final_labs=pd.DataFrame()\n",
    "\n",
    "\n",
    "# meds=meds_new.sort_values(by=['start_time'])\n",
    "# ing=ing_new.sort_values(by=['start_time'])\n",
    "proc=proc_new.sort_values(by=['start_time'])\n",
    "# out=out_new.sort_values(by=['start_time'])\n",
    "# chart=chart_new.sort_values(by=['start_time'])\n",
    "# labs=labs_new.sort_values(by=['start_time'])\n",
    "\n",
    "hids=data_new['stay_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1fb700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = pd.concat([chart_new[['stay_id', 'itemid']], labs_new[['stay_id', 'itemid']]], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef5c8ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the item_ids we are interested in\n",
    "required_item_ids = {220045, 225668, 50813, 220050, 220051}\n",
    "\n",
    "\n",
    "# Find the stay_ids that have all the required item_ids at least once\n",
    "valid_stay_ids = sample_data[sample_data['itemid'].isin(required_item_ids)].groupby('stay_id')['itemid'].nunique()\n",
    "valid_stay_ids = valid_stay_ids[valid_stay_ids == len(required_item_ids)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25ef7606",
   "metadata": {},
   "outputs": [],
   "source": [
    "meds_1 = meds_new[meds_new['stay_id'].isin(valid_stay_ids)]\n",
    "ing_1 = ing_new[ing_new['stay_id'].isin(valid_stay_ids)]\n",
    "proc_1 = proc_new[proc_new['stay_id'].isin(valid_stay_ids)]\n",
    "# out_1 = out[out_new['stay_id'].isin(valid_stay_ids)]\n",
    "chart_1 = chart_new[chart_new['stay_id'].isin(valid_stay_ids)]\n",
    "labs_1 = labs_new[labs_new['stay_id'].isin(valid_stay_ids)]\n",
    "data_1 = data_new[data_new['stay_id'].isin(valid_stay_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2998863"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#예상 관측치 수\n",
    "data_1['los'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/Users/DAHS/MIMIC-IV-Data-Pipeline/MIMIC_pipeline/Case Labeling/mimic_df.csv.gz', index_col = 0, compression='gzip')\n",
    "valid_stay_ids = dataset.stay_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_1 = proc_new[proc_new['stay_id'].isin(valid_stay_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "622752da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tabularize EHR for total stay 10,268:  50%|█████     | 10336/20549 [06:34<06:29, 26.20it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\DAHS\\Desktop\\MIMIC_IV_CIRC(12h)\\mainPipeline_step2.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/DAHS/Desktop/MIMIC_IV_CIRC%2812h%29/mainPipeline_step2.ipynb#X12sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m df2\u001b[39m=\u001b[39mdf2\u001b[39m.\u001b[39msort_index()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/DAHS/Desktop/MIMIC_IV_CIRC%2812h%29/mainPipeline_step2.ipynb#X12sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m df2\u001b[39m=\u001b[39mdf2\u001b[39m.\u001b[39mfillna(\u001b[39m0\u001b[39m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/DAHS/Desktop/MIMIC_IV_CIRC%2812h%29/mainPipeline_step2.ipynb#X12sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m df2[df2\u001b[39m>\u001b[39;49m\u001b[39m0\u001b[39;49m]\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/DAHS/Desktop/MIMIC_IV_CIRC%2812h%29/mainPipeline_step2.ipynb#X12sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m feat_df\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(feat)\u001b[39m-\u001b[39m\u001b[39mset\u001b[39m(df2\u001b[39m.\u001b[39mcolumns)))\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/DAHS/Desktop/MIMIC_IV_CIRC%2812h%29/mainPipeline_step2.ipynb#X12sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m df2\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mconcat([df2,feat_df],axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\MIMIC\\lib\\site-packages\\pandas\\core\\frame.py:3966\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3963\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_slice(indexer, value)\n\u001b[0;32m   3965\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, DataFrame) \u001b[39mor\u001b[39;00m \u001b[39mgetattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m-> 3966\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_frame(key, value)\n\u001b[0;32m   3967\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, (Series, np\u001b[39m.\u001b[39mndarray, \u001b[39mlist\u001b[39m, Index)):\n\u001b[0;32m   3968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array(key, value)\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\MIMIC\\lib\\site-packages\\pandas\\core\\frame.py:4089\u001b[0m, in \u001b[0;36mDataFrame._setitem_frame\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4087\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_inplace_setting(value)\n\u001b[0;32m   4088\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_setitem_copy()\n\u001b[1;32m-> 4089\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_where(\u001b[39m-\u001b[39;49mkey, value, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\MIMIC\\lib\\site-packages\\pandas\\core\\generic.py:9733\u001b[0m, in \u001b[0;36mNDFrame._where\u001b[1;34m(self, cond, other, inplace, axis, level)\u001b[0m\n\u001b[0;32m   9728\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   9729\u001b[0m     \u001b[39m# we may have different type blocks come out of putmask, so\u001b[39;00m\n\u001b[0;32m   9730\u001b[0m     \u001b[39m# reconstruct the block manager\u001b[39;00m\n\u001b[0;32m   9732\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_inplace_setting(other)\n\u001b[1;32m-> 9733\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mputmask(mask\u001b[39m=\u001b[39;49mcond, new\u001b[39m=\u001b[39;49mother, align\u001b[39m=\u001b[39;49malign)\n\u001b[0;32m   9734\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\n\u001b[0;32m   9735\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(result)\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\MIMIC\\lib\\site-packages\\pandas\\core\\internals\\managers.py:410\u001b[0m, in \u001b[0;36mBaseBlockManager.putmask\u001b[1;34m(self, mask, new, align)\u001b[0m\n\u001b[0;32m    407\u001b[0m     align_keys \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    408\u001b[0m     new \u001b[39m=\u001b[39m extract_array(new, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 410\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\n\u001b[0;32m    411\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mputmask\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    412\u001b[0m     align_keys\u001b[39m=\u001b[39;49malign_keys,\n\u001b[0;32m    413\u001b[0m     mask\u001b[39m=\u001b[39;49mmask,\n\u001b[0;32m    414\u001b[0m     new\u001b[39m=\u001b[39;49mnew,\n\u001b[0;32m    415\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\MIMIC\\lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(b, f)(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\MIMIC\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1021\u001b[0m, in \u001b[0;36mBlock.putmask\u001b[1;34m(self, mask, new)\u001b[0m\n\u001b[0;32m   1019\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1020\u001b[0m     casted \u001b[39m=\u001b[39m np_can_hold_element(values\u001b[39m.\u001b[39mdtype, new)\n\u001b[1;32m-> 1021\u001b[0m     putmask_without_repeat(values\u001b[39m.\u001b[39;49mT, mask, casted)\n\u001b[0;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m]\n\u001b[0;32m   1023\u001b[0m \u001b[39mexcept\u001b[39;00m LossySetitemError:\n",
      "File \u001b[1;32mc:\\Users\\DAHS\\anaconda3\\envs\\MIMIC\\lib\\site-packages\\pandas\\core\\array_algos\\putmask.py:95\u001b[0m, in \u001b[0;36mputmask_without_repeat\u001b[1;34m(values, mask, new)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot assign mismatch length to masked array\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     np\u001b[39m.\u001b[39;49mputmask(values, mask, new)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mputmask\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('mode.chained_assignment',  None) \n",
    "\n",
    "# final_meds = meds[(meds['start_time']>0)&(meds['stop_time']>0)].copy()\n",
    "# final_ing= ing[(ing['start_time']>0)&(ing['stop_time']>0)].copy()\n",
    "final_proc= proc.copy() \n",
    "# final_out= out.copy()\n",
    "# final_chart= chart.copy()\n",
    "# final_labs= labs.copy()\n",
    "\n",
    "feat_med = False\n",
    "feat_ing = False\n",
    "feat_proc = True\n",
    "feat_out = False\n",
    "feat_chart = False\n",
    "impute = False\n",
    "feat_lab = False\n",
    "\n",
    "for hid in tqdm(valid_stay_ids, desc = 'Tabularize EHR for total stay 10,268'):\n",
    "    grp=data[data['stay_id']==hid]\n",
    "    los = int(grp['los'].values)\n",
    "    \n",
    "    if not os.path.exists(local+\"/csv/\"+str(hid)):\n",
    "        os.makedirs(local+\"/csv/\"+str(hid))\n",
    "    \n",
    "    dyn_csv=pd.DataFrame()\n",
    "    \n",
    "    ###MEDS\n",
    "    if(feat_med):\n",
    "        feat=final_meds['itemid'].unique()\n",
    "        df2=final_meds[final_meds['stay_id']==hid]\n",
    "        if df2.shape[0]==0:\n",
    "            amount=pd.DataFrame(np.zeros([los,len(feat)]),columns=feat)\n",
    "            amount=amount.fillna(0)\n",
    "            amount.columns=pd.MultiIndex.from_product([[\"MEDS\"], amount.columns])\n",
    "        else:\n",
    "            amount=df2.pivot_table(index='start_time',columns='itemid',values='amount')\n",
    "            df2=df2.pivot_table(index='start_time',columns='itemid',values='stop_time')\n",
    "\n",
    "            add_indices = pd.Index(range(los)).difference(df2.index)\n",
    "            add_df = pd.DataFrame(index=add_indices, columns=df2.columns).fillna(np.nan)\n",
    "            df2=pd.concat([df2, add_df])\n",
    "            df2=df2.sort_index()\n",
    "            df2=df2.ffill()\n",
    "            df2=df2.fillna(0)\n",
    "\n",
    "            amount=pd.concat([amount, add_df])\n",
    "            amount=amount.sort_index()\n",
    "            amount=amount.ffill()\n",
    "            amount=amount.fillna(0)\n",
    " \n",
    "            df2.iloc[:,0:]=df2.iloc[:,0:].sub(df2.index,0)\n",
    "            df2[df2>0]=1\n",
    "            df2[df2<0]=0\n",
    "       \n",
    "            amount.iloc[:,0:]=df2.iloc[:,0:]*amount.iloc[:,0:]\n",
    "            feat_df=pd.DataFrame(columns=list(set(feat)-set(amount.columns)))\n",
    "            amount=pd.concat([amount,feat_df],axis=1)\n",
    "\n",
    "\n",
    "            amount=amount[feat]\n",
    "            amount=amount.fillna(0)\n",
    "            amount.columns=pd.MultiIndex.from_product([[\"MEDS\"], amount.columns])\n",
    "     \n",
    "            \n",
    "        if(dyn_csv.empty):\n",
    "            dyn_csv=amount\n",
    "        else:\n",
    "            dyn_csv=pd.concat([dyn_csv,amount],axis=1)\n",
    "        \n",
    "    \n",
    "    ###INGS\n",
    "    if(feat_ing):\n",
    "        feat=final_ing['itemid'].unique()\n",
    "        df2=final_ing[final_ing['stay_id']==hid]\n",
    "        if df2.shape[0]==0:\n",
    "            amount=pd.DataFrame(np.zeros([los,len(feat)]),columns=feat)\n",
    "            amount=amount.fillna(0)\n",
    "            amount.columns=pd.MultiIndex.from_product([[\"INGS\"], amount.columns])\n",
    "        else:\n",
    "            amount=df2.pivot_table(index='start_time',columns='itemid',values='amount')\n",
    "            df2=df2.pivot_table(index='start_time',columns='itemid',values='stop_time')\n",
    "            add_indices = pd.Index(range(los)).difference(df2.index)\n",
    "            add_df = pd.DataFrame(index=add_indices, columns=df2.columns).fillna(np.nan)\n",
    "            df2=pd.concat([df2, add_df])\n",
    "            df2=df2.sort_index()\n",
    "            df2=df2.ffill()\n",
    "            df2=df2.fillna(0)\n",
    "\n",
    "            amount=pd.concat([amount, add_df])\n",
    "            amount=amount.sort_index()\n",
    "            amount=amount.ffill()\n",
    "            amount=amount.fillna(0)\n",
    "            \n",
    "            df2.iloc[:,0:]=df2.iloc[:,0:].sub(df2.index,0)\n",
    "            df2[df2>0]=1\n",
    "            df2[df2<0]=0\n",
    "\n",
    "            amount.iloc[:,0:]=df2.iloc[:,0:]*amount.iloc[:,0:]\n",
    "            feat_df=pd.DataFrame(columns=list(set(feat)-set(amount.columns)))\n",
    "            amount=pd.concat([amount,feat_df],axis=1)\n",
    "\n",
    "            amount=amount[feat]\n",
    "            amount=amount.fillna(0)\n",
    "            \n",
    "            amount.columns=pd.MultiIndex.from_product([[\"INGS\"], amount.columns])\n",
    "            \n",
    "        if(dyn_csv.empty):\n",
    "            dyn_csv=amount\n",
    "        else:\n",
    "            dyn_csv=pd.concat([dyn_csv,amount],axis=1)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    ###PROCS\n",
    "    if(feat_proc):\n",
    "        feat=final_proc['itemid'].unique()\n",
    "        df2=final_proc[final_proc['stay_id']==hid]\n",
    "        if df2.shape[0]==0:\n",
    "            amount=pd.DataFrame(np.zeros([los,len(feat)]),columns=feat)\n",
    "            amount=amount.fillna(0)\n",
    "            amount.columns=pd.MultiIndex.from_product([[\"PROC\"], amount.columns])\n",
    "        else:\n",
    "            df2['val']=1\n",
    "            amount=df2.pivot_table(index='start_time',columns='itemid',values='val')\n",
    "            df2=df2.pivot_table(index='start_time',columns='itemid',values='stop_time')\n",
    "            add_indices = pd.Index(range(los)).difference(df2.index)\n",
    "            add_df = pd.DataFrame(index=add_indices, columns=df2.columns).fillna(np.nan)\n",
    "            \n",
    "            df2=pd.concat([df2, add_df])\n",
    "            df2=df2.sort_index()\n",
    "            df2=df2.fillna(0)\n",
    "            df2[df2>0]=1\n",
    "            \n",
    "            amount=pd.concat([amount, add_df])\n",
    "            amount=amount.sort_index()\n",
    "            amount=amount.ffill()\n",
    "            amount=amount.fillna(0)\n",
    "            \n",
    "            df2.iloc[:,0:]=df2.iloc[:,0:].sub(df2.index,0)\n",
    "            df2[df2>0]=1\n",
    "            df2[df2<0]=0\n",
    "\n",
    "            amount.iloc[:,0:]=df2.iloc[:,0:]*amount.iloc[:,0:]\n",
    "            feat_df=pd.DataFrame(columns=list(set(feat)-set(amount.columns)))\n",
    "            amount=pd.concat([amount,feat_df],axis=1)\n",
    "\n",
    "            amount=amount[feat]\n",
    "            amount=amount.fillna(0)\n",
    "            \n",
    "            amount.columns=pd.MultiIndex.from_product([[\"PROC\"], amount.columns])\n",
    "            \n",
    "        if(dyn_csv.empty):\n",
    "            dyn_csv=amount\n",
    "        else:\n",
    "            dyn_csv=pd.concat([dyn_csv,amount],axis=1)\n",
    "        \n",
    "        \n",
    "    ###OUT\n",
    "    if(feat_out):\n",
    "        feat=final_out['itemid'].unique()\n",
    "        df2=final_out[final_out['stay_id']==hid]\n",
    "    \n",
    "        if df2.shape[0]==0:\n",
    "            val=pd.DataFrame(np.zeros([los,len(feat)]),columns=feat)\n",
    "            val=val.fillna(0)\n",
    "            val.columns=pd.MultiIndex.from_product([[\"OUT\"], val.columns])\n",
    "        else:\n",
    "            val=df2.pivot_table(index='start_time',columns='itemid',values='value')\n",
    "            df2['val']=1\n",
    "            df2=df2.pivot_table(index='start_time',columns='itemid',values='val')\n",
    "\n",
    "            add_indices = pd.Index(range(los)).difference(df2.index)\n",
    "            add_df = pd.DataFrame(index=add_indices, columns=df2.columns).fillna(np.nan)\n",
    "            df2=pd.concat([df2, add_df])\n",
    "            df2=df2.sort_index()\n",
    "            df2=df2.fillna(0)\n",
    "\n",
    "            val=pd.concat([val, add_df])\n",
    "            val=val.sort_index()\n",
    "            val=val.fillna(0)\n",
    "            \n",
    "            df2[df2>0]=1\n",
    "            df2[df2<0]=0\n",
    "\n",
    "            feat_df=pd.DataFrame(columns=list(set(feat)-set(val.columns)))\n",
    "            val=pd.concat([val,feat_df],axis=1)\n",
    "\n",
    "            val=val[feat]\n",
    "            val=val.fillna(0)\n",
    "            val.columns=pd.MultiIndex.from_product([[\"OUT\"], val.columns])\n",
    "        \n",
    "        if(dyn_csv.empty):\n",
    "            dyn_csv=val\n",
    "        else:\n",
    "            dyn_csv=pd.concat([dyn_csv,val],axis=1)\n",
    "            \n",
    "        \n",
    "    ###CHART\n",
    "    if(feat_chart):\n",
    "        feat=final_chart['itemid'].unique()\n",
    "        df2=final_chart[final_chart['stay_id']==hid]\n",
    "        if df2.shape[0]==0:\n",
    "            val=pd.DataFrame(np.zeros([los,len(feat)]),columns=feat)\n",
    "            val=val.fillna(0)\n",
    "            val.columns=pd.MultiIndex.from_product([[\"CHART\"], val.columns])\n",
    "        else:\n",
    "            val=df2.pivot_table(index='start_time',columns='itemid',values='valuenum')\n",
    "            df2['val']=1\n",
    "            df2=df2.pivot_table(index='start_time',columns='itemid',values='val')\n",
    "            #print(df2.shape)\n",
    "            add_indices = pd.Index(range(los)).difference(df2.index)\n",
    "            add_df = pd.DataFrame(index=add_indices, columns=df2.columns).fillna(np.nan)\n",
    "            df2=pd.concat([df2, add_df])\n",
    "            df2=df2.sort_index()\n",
    "            df2=df2.fillna(0)\n",
    "\n",
    "            val=pd.concat([val, add_df])\n",
    "            val=val.sort_index()\n",
    "            if impute:\n",
    "                val=val.ffill()\n",
    "\n",
    "            df2[df2>0]=1\n",
    "            df2[df2<0]=0\n",
    "\n",
    "            feat_df=pd.DataFrame(columns=list(set(feat)-set(val.columns)))\n",
    "            val=pd.concat([val,feat_df],axis=1)\n",
    "\n",
    "            val=val[feat]\n",
    "            val.columns=pd.MultiIndex.from_product([[\"CHART\"], val.columns])\n",
    "        \n",
    "        if(dyn_csv.empty):\n",
    "            dyn_csv=val\n",
    "        else:\n",
    "            dyn_csv=pd.concat([dyn_csv,val],axis=1)\n",
    "    \n",
    "    ###LABS\n",
    "    if(feat_lab):\n",
    "        feat=final_labs['itemid'].unique()\n",
    "        df2=final_labs[final_labs['stay_id']==hid]\n",
    "        if df2.shape[0]==0:\n",
    "            val=pd.DataFrame(np.zeros([los,len(feat)]),columns=feat)\n",
    "            val=val.fillna(0)\n",
    "            val.columns=pd.MultiIndex.from_product([[\"LAB\"], val.columns])\n",
    "        else:\n",
    "            val=df2.pivot_table(index='start_time',columns='itemid',values='valuenum')\n",
    "            df2['val']=1\n",
    "            df2=df2.pivot_table(index='start_time',columns='itemid',values='val')\n",
    "            add_indices = pd.Index(range(los)).difference(df2.index)\n",
    "            add_df = pd.DataFrame(index=add_indices, columns=df2.columns).fillna(np.nan)\n",
    "            df2=pd.concat([df2, add_df])\n",
    "            df2=df2.sort_index()\n",
    "            df2=df2.fillna(0)\n",
    "\n",
    "            val=pd.concat([val, add_df])\n",
    "            val=val.sort_index()\n",
    "            if impute:\n",
    "                val=val.ffill()\n",
    "\n",
    "            df2[df2>0]=1\n",
    "            df2[df2<0]=0\n",
    "            \n",
    "            feat_df=pd.DataFrame(columns=list(set(feat)-set(val.columns)))\n",
    "            val=pd.concat([val,feat_df],axis=1)\n",
    "\n",
    "            val=val[feat]\n",
    "            val.columns=pd.MultiIndex.from_product([[\"LAB\"], val.columns])\n",
    "        \n",
    "        if(dyn_csv.empty):\n",
    "            dyn_csv=val\n",
    "        else:\n",
    "            dyn_csv=pd.concat([dyn_csv,val],axis=1)\n",
    "    \n",
    "    #Save temporal data to csv\n",
    "    dyn_csv.to_csv(local+'/csv/'+str(hid)+'/dynamic_proc.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f941fc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_stay_ids\n",
    "\n",
    "data_1.to_csv(local+'/demo.csv')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
